openapi: 3.1.0
info:
  title: "KoboldCPP Model Switcher"
  version: 0.2.0-pre.3
paths:
  /probe:
    get:
      description: Check plugin status
      responses:
        "204":
          description: Plugin is running
      tags:
        - Plugin info
  /redoc:
    get:
      description: Get API documentation
      responses:
        "200":
          description: Returns ReDoc for plugin API
      tags:
        - Plugin info
  /model:
    get:
      summary: Get model status
      description: Returns details about running model
      responses:
        "200":
          description: Running model info
          content:
            "application/json":
              schema:
                "$ref": "#/components/schemas/modelInfo"
      tags:
        - Model Operations
    put:
      summary: Start or restart KoboldCpp with given model
      description: |
        Initiate start or restart of KoboldCpp. Changes status to `loading`.

        This is non-blocking operation though if there is a loaded model,
        operation will be blocked until old model is deleted.

        You have to wait for status to reach `online` to make sure koboldcpp accept connections.
      requestBody:
        content:
          "application/json":
            schema:
              "$ref": "#/components/schemas/modelRun"
      responses:
        "201":
          description: KoboldCpp started successfully
        "400":
          description: Error in requiest body
          "$ref": "#/components/responses/errorResponse"
        "409":
          description: Current model status forbids creation
          "$ref": "#/components/responses/errorResponse"
      tags:
        - Model Operations
    delete:
      summary: Stop managed KoboldCpp
      description: |
        Initialize stopping KoboldCpp instance. Changes status to `stopping`.

        You have to wait for status to reach `offline` to make sure koboldcpp is down.
      responses:
        "204":
          description: KoboldCpp stopped successfully
        "409":
          description: Current model status forbids deletion
          "$ref": "#/components/responses/errorResponse"
      tags:
        - Model Operations
components:
  responses:
    errorResponse:
      description: Response with error message
      content:
        "application/json":
          schema:
            "$ref": "#/components/schemas/errorResponse"

  schemas:
    errorResponse:
      type: object
      properties:
        error:
          type: string
          description: error message
      required:
        - error
    modelRun:
      type: object
      properties:
        model:
          type: string
          description: Relative path to the model GGUF file to be run
          example: nvidia_Llama-3_3-Nemotron-Super-49B-v1-Q4_K_S.gguf
        binaryPath:
          type: string
          description: Relative path to koboldcpp executable (now ignored)
          example: koboldcpp-linux-x64-cuda1210
        contextSize:
          type: number
          enum:
            - 256
            - 512
            - 1024
            - 2048
            - 3072
            - 4096
            - 6144
            - 8192
            - 10240
            - 12288
            - 14336
            - 16384
            - 20480
            - 24576
            - 28672
            - 32768
            - 40960
            - 49152
            - 57344
            - 65536
            - 81920
            - 98304
            - 114688
            - 131072
        gpuLayers:
          type: number
          description: Number of layers to offload to GPU
          example: 12288
        threads:
          type: number
          description: Threads to be used on CPU (1 is enough if model is fully offloaded to GPU)
          example: 81
        tensorSplit:
          type: array
          description: Tensor split for multi-GPU setups
          example: [29, 52]
          items:
            type: number
      required:
        - model
      example:
        {
          "binaryPath": "koboldcpp-linux-x64-cuda1210",
          "contextSize": 12288,
          "gpuLayers": 81,
          "model": "nvidia_Llama-3_3-Nemotron-Super-49B-v1-Q4_K_S.gguf",
          "threads": 1,
          "tensorSplit": [29, 52],
        }
    modelInfo:
      type: object
      description: Info about currently running model
      example:
        {
          "status": "online",
          "model": "nvidia_Llama-3_3-Nemotron-Super-49B-v1-Q4_K_S",
        }
      properties:
        model:
          type: string
          description: Name of the currently loaded model
          example: "nvidia_Llama-3_3-Nemotron-Super-49B-v1-Q4_K_S"
        status:
          type: string
          description: Status of the LLM loaded by Kobold
          example: online
          enum: ["offline", "loading", "online", "stopping", "failed"]
        error:
          type: string
          example: SIGTERM
          description: Details of execution error
      required:
        - status
